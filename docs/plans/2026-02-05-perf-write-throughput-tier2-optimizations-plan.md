---
title: "perf: Write throughput Tier 2 optimizations"
type: perf
date: 2026-02-05
---

# perf: Write Throughput Tier 2 Optimizations

## Overview

Four medium-complexity optimizations targeting the write and read hot paths, building on the Tier 1 foundation (PR #12). These reduce per-operation overhead by eliminating redundant I/O, optimizing serialization, and skipping unnecessary network round-trips.

## Current Baseline (post-Tier 1, 10KB payloads, 3-node cluster)

| Scenario | Throughput | p50 | Notes |
|----------|-----------|-----|-------|
| write-1u | 12.3 req/s | 2ms | Sequential to leader |
| write-10u | 127.1 req/s | 2ms | 10 concurrent users |
| read-1u | 1,501 req/s | 1ms | With read barrier |
| read-10u | 3,230 req/s | 2ms | With read barrier |
| mixed-10u | 312 req/s | 1ms | 70% read, 30% write |
| sequential PUT | 314 req/s | 3ms | `benchmark_configs.py` direct to leader |

## Changes

### Change 1: Remove Post-Write Poll Loop

**Impact:** MEDIUM — saves 10-50ms per write (up to 5 polls x 10ms)
**Complexity:** LOW
**Risk:** LOW

**Problem:** `ConfigController.Set` (lines 128-143) polls LiteDB up to 5 times with 10ms delays after Raft replication to read back the stored entry. This exists solely to populate the response body with the version number and timestamp that LiteDB generates on apply.

**Current flow:**
```
Client PUT → Raft replicate (quorum) → poll LiteDB 5x → return ConfigEntryDto
```

**Proposed flow:**
```
Client PUT → Raft replicate (quorum) → return response from command data
```

**Files:**
- `src/Confman.Api/Controllers/ConfigController.cs:127-151` — Remove poll loop, construct response from command data

**Implementation:**

```csharp
// src/Confman.Api/Controllers/ConfigController.cs:117-151
// BEFORE:
var replicated = await _raft.ReplicateAsync(command, ct);
if (!replicated) { /* ... error ... */ }

ConfigEntry? entry = null;
for (var i = 0; i < 5 && entry is null; i++)
{
    entry = await _store.GetAsync(ns, key, ct);
    if (entry is null) await Task.Delay(10, ct);
}
// ... error handling for null entry ...
return Ok(ConfigEntryDto.FromModel(entry));

// AFTER:
var replicated = await _raft.ReplicateAsync(command, ct);
if (!replicated) { /* ... error ... */ }

// Return command data directly — Raft commit guarantees durability
// Version is not available until state machine applies; omit from response
return Ok(new
{
    @namespace = ns,
    key,
    value = request.Value,
    type = request.Type ?? "string",
    updatedBy = author,
    updatedAt = command.Timestamp,
    committed = true
});
```

**Design decisions:**
- Return `committed: true` to signal the write is durable but may not yet be readable
- Omit `version` — it's generated by LiteDB on apply and not available at commit time
- Keep the same 200 OK status code (PUT is idempotent)
- ReadBarrier on subsequent GETs ensures the applied value is visible

**Also apply to:** `NamespacesController.Set` (lines 96-125) — has the same pattern with a pre-write existence check for 200 vs 201 status code. Remove that check too and always return 200.

**Why this is safe:** Discussed in detail earlier in the session. The write is committed to the Raft majority WAL. ReadBarrier on GETs ensures clients see the applied value. For a config service, sub-second apply lag is acceptable.

**Tests to update:**
- Any integration tests that assert `version` in PUT response need updating
- Add test that PUT returns command data without requiring store read

---

### Change 2: Eliminate Read-Before-Write in Commands

**Impact:** MEDIUM — saves 1 LiteDB read per state machine apply (on ALL nodes)
**Complexity:** MEDIUM
**Risk:** LOW-MEDIUM (audit implications)

**Problem:** When audit is enabled, every command reads the existing entry before writing to:
1. Determine the audit action (`ConfigCreated` vs `ConfigUpdated`)
2. Capture the old value for the audit event

This happens on ALL nodes during state machine apply — not just the leader. For a 3-node cluster writing 100 keys, that's 300 extra reads.

**Current flow (per node, per apply):**
```
SetConfigCommand.ApplyAsync:
  → store.GetAsync (READ #1: get existing for audit old value)
  → store.SetWithAuditAsync:
       → _configs.FindOne (READ #2: get existing for version)
       → _configs.Update or Insert (WRITE)
       → _audit.Upsert (WRITE)
```

**Proposed flow:**
```
SetConfigCommand.ApplyAsync:
  → store.UpsertWithAuditAsync:
       → _configs.FindOne (READ: get existing for version + old value)
       → _configs.Update or Insert (WRITE)
       → _audit.Upsert (WRITE)
```

**Key insight:** The read in `SetWithAuditAsync` (for versioning) and the read in `SetConfigCommand.ApplyAsync` (for audit old value) query the same key. Merge them into one.

**Files:**
- `src/Confman.Api/Cluster/Commands/SetConfigCommand.cs` — Remove `store.GetAsync` call, pass audit metadata to store
- `src/Confman.Api/Cluster/Commands/DeleteConfigCommand.cs` — Same pattern
- `src/Confman.Api/Cluster/Commands/SetNamespaceCommand.cs` — Same pattern
- `src/Confman.Api/Cluster/Commands/DeleteNamespaceCommand.cs` — Same pattern
- `src/Confman.Api/Storage/LiteDbConfigStore.cs` — Add `UpsertWithAuditAsync` that returns old value
- `src/Confman.Api/Storage/IConfigStore.cs` — Add interface method

**Implementation approach:**

```csharp
// src/Confman.Api/Storage/IConfigStore.cs — New method
Task<ConfigEntry?> SetWithAuditAsync(ConfigEntry entry, string author, DateTimeOffset timestamp, CancellationToken ct = default);

// src/Confman.Api/Storage/LiteDbConfigStore.cs — Implementation
// Single read serves both versioning AND audit old-value capture
public async Task<ConfigEntry?> SetWithAuditAsync(ConfigEntry entry, string author, DateTimeOffset timestamp, CancellationToken ct = default)
{
    await _dbSemaphore.WaitAsync(ct);
    try
    {
        var existing = _configs.FindOne(x => x.Namespace == entry.Namespace && x.Key == entry.Key);

        _db.BeginTrans();
        try
        {
            if (existing is not null)
            {
                entry.Id = existing.Id;
                entry.Version = existing.Version + 1;
                _configs.Update(entry);
            }
            else
            {
                entry.Version = 1;
                _configs.Insert(entry);
            }

            if (_auditEnabled)
            {
                var action = existing is null ? AuditAction.ConfigCreated : AuditAction.ConfigUpdated;
                _audit.Upsert(new AuditEvent
                {
                    Id = AuditIdGenerator.Generate(timestamp, entry.Namespace, entry.Key, action),
                    Timestamp = timestamp,
                    Action = action,
                    Actor = author,
                    Namespace = entry.Namespace,
                    Key = entry.Key,
                    OldValue = existing?.Value,
                    NewValue = entry.Value
                });
            }

            _db.Commit();
            return existing; // Return old value for callers that need it
        }
        catch
        {
            _db.Rollback();
            throw;
        }
    }
    finally
    {
        _dbSemaphore.Release();
    }
}
```

```csharp
// src/Confman.Api/Cluster/Commands/SetConfigCommand.cs — Simplified
public async Task ApplyAsync(IConfigStore store, bool auditEnabled = true, CancellationToken ct = default)
{
    var entry = new ConfigEntry
    {
        Namespace = Namespace,
        Key = Key,
        Value = Value,
        Type = Type,
        UpdatedAt = Timestamp,
        UpdatedBy = Author
    };

    // Single call — store handles versioning, audit, and old-value capture internally
    await store.SetWithAuditAsync(entry, Author, Timestamp, ct);
}
```

**Audit old-value is preserved:** The existing `SetWithAuditAsync` already does a `FindOne` for versioning. We reuse that read to also capture the old value for audit. Zero reads eliminated from the audit path — we just stop doing the redundant second read in the command layer.

**Tests to update:**
- Command unit tests that mock `store.GetAsync` before `store.SetWithAuditAsync`
- Verify audit events still contain old values

---

### Change 3: Optimize Raft Serialization (UTF-8 Direct)

**Impact:** LOW-MEDIUM — eliminates string allocation per replication
**Complexity:** LOW
**Risk:** LOW

**Problem:** `RaftService.ReplicateAsync` (lines 80-81) serializes commands via:
```csharp
var json = JsonSerializer.Serialize(command);       // string allocation
var bytes = System.Text.Encoding.UTF8.GetBytes(json); // byte[] allocation
```

This creates an intermediate `string` that is immediately converted to `byte[]`. `SerializeToUtf8Bytes` skips the string entirely.

**Proposed:**
```csharp
// src/Confman.Api/Cluster/RaftService.cs:80-81
// BEFORE:
var json = JsonSerializer.Serialize(command);
var bytes = System.Text.Encoding.UTF8.GetBytes(json);

// AFTER:
var bytes = JsonSerializer.SerializeToUtf8Bytes(command);
```

**Why not MessagePack (yet):** The SpecFlow analysis correctly identifies that MessagePack requires a two-phase rolling upgrade strategy — all nodes must support dual-format deserialization before any node starts writing MessagePack. This is a Tier 3 effort. The UTF-8 optimization gives ~30% of the benefit with zero compatibility risk.

**Files:**
- `src/Confman.Api/Cluster/RaftService.cs:80-81` — One line change

**Tests:** Existing tests cover serialization round-trip. No changes needed.

---

### Change 4: Leader Lease for Reads

**Impact:** MEDIUM — eliminates heartbeat round-trip for reads on leader node
**Complexity:** LOW-MEDIUM
**Risk:** MEDIUM (clock drift sensitivity)

**Problem:** `ReadBarrierMiddleware` calls `cluster.ApplyReadBarrierAsync()` for every GET request, even on the leader node. This sends a heartbeat to all followers and waits for majority acknowledgment — typically 1-5ms on localhost, but 10-50ms on a real network.

DotNext exposes `IRaftCluster.TryGetLeaseToken(out CancellationToken token)` which returns true if the current node is leader AND the lease hasn't expired. The lease is valid as long as the leader has received recent heartbeat acknowledgments — no extra round-trip needed.

**Current flow (leader node):**
```
GET → ReadBarrier → ApplyReadBarrierAsync → heartbeat to all followers → wait quorum → read LiteDB
```

**Proposed flow (leader node):**
```
GET → ReadBarrier → TryGetLeaseToken? → if valid, skip barrier → read LiteDB
```

**Follower behavior unchanged:** Followers cannot use the lease (they're not the leader). They fall through to the existing `ApplyReadBarrierAsync` or stale mode.

**Files:**
- `src/Confman.Api/Middleware/ReadBarrierMiddleware.cs:64-68` — Add lease check before barrier

**Implementation:**

```csharp
// src/Confman.Api/Middleware/ReadBarrierMiddleware.cs — Inside InvokeAsync, before the barrier try/catch
// Fast path: leader with valid lease can skip the barrier entirely
if (cluster.TryGetLeaseToken(out var leaseToken) && !leaseToken.IsCancellationRequested)
{
    _logger.LogDebug("Leader lease valid, skipping read barrier for {Method} {Path}",
        context.Request.Method, context.Request.Path);
    await _next(context);
    return;
}

// Slow path: follower or expired lease — use full barrier
var stopwatch = Stopwatch.StartNew();
var barrierSucceeded = false;
// ... existing code ...
```

**Clock drift consideration:** DotNext's lease is conservative — it's tied to the heartbeat interval and `clockDriftBound` config (default 1.0). With `heartbeatThreshold: 0.3` and election timeout 150-300ms, the lease window is ~45-90ms. A lease is only valid if heartbeat acks were received within this window.

**Configuration:** The `clockDriftBound` setting in `ClusterMemberConfiguration` (default 1.0 = no extra drift margin) can be increased if nodes have poor clock sync. For local development on a single machine, 1.0 is fine.

**No appsettings.json change needed** — the DotNext defaults are appropriate. Add a config flag to disable the optimization if issues arise:

```json
{
  "ReadBarrier": {
    "UseLeaderLease": true
  }
}
```

**Tests:**
- Unit test: verify lease bypass works when `TryGetLeaseToken` returns true
- Unit test: verify fallback to barrier when `TryGetLeaseToken` returns false
- Cluster test: verify reads on leader don't call `ApplyReadBarrierAsync` when lease valid

---

## Implementation Order

```
Change 3 (UTF-8 serialization) ──► independent, 1-line, zero risk
Change 1 (remove poll loop)    ──► independent, controller-only
Change 2 (merge reads)         ──► touches store interface + all commands
Change 4 (leader lease)        ──► independent, middleware-only
```

Recommended sequence: **3 → 1 → 2 → 4**

- **Change 3** first: trivial, warms up the branch
- **Change 1** second: simple controller refactor, measurable impact
- **Change 2** third: most files touched, needs careful test updates
- **Change 4** last: involves distributed systems semantics, test in cluster

## Acceptance Criteria

- [x] `RaftService.ReplicateAsync` uses `SerializeToUtf8Bytes` directly
- [x] `ConfigController.Set` returns immediately after `ReplicateAsync` — no poll loop
- [x] `NamespacesController.Set` returns immediately after `ReplicateAsync` — no pre-read
- [x] `SetConfigCommand.ApplyAsync` does NOT call `store.GetAsync` separately
- [x] `DeleteConfigCommand.ApplyAsync` does NOT call `store.GetAsync` separately
- [x] `SetNamespaceCommand.ApplyAsync` does NOT call `store.GetNamespaceAsync` separately
- [x] `DeleteNamespaceCommand.ApplyAsync` does NOT call `store.GetNamespaceAsync` separately
- [x] Audit events still capture old values (verified by test)
- [x] `ReadBarrierMiddleware` uses `TryGetLeaseToken` on leader before calling `ApplyReadBarrierAsync`
- [x] Leader lease bypass configurable via `ReadBarrier:UseLeaderLease` (default true)
- [x] All 57 existing tests pass
- [ ] Locust benchmark shows measurable improvement vs Tier 1 baseline
- [ ] `benchmark_configs.py` sequential write throughput ≥ 314 req/s (no regression)

## Testing Strategy

1. **Unit tests:** Verify each change in isolation
   - Command tests: assert no `store.GetAsync` calls when audit data flows through store
   - Controller tests: assert no `store.GetAsync` calls after replication
   - Middleware tests: assert `TryGetLeaseToken` checked before barrier
2. **Existing test suite:** All 57 tests pass after each change
3. **Cluster benchmark:** Run Locust large tier (10KB payloads) after all changes
4. **Sequential benchmark:** Run `benchmark_configs.py write -c 500 -n bench --unlimited -s 1KB`

## What This Does NOT Include

- **MessagePack serialization** — deferred to Tier 3 (requires rolling upgrade strategy)
- **Write batching / group commit** — deferred to Tier 3 (architectural change)
- **RocksDB replacement** — deferred to Tier 3 (full storage rewrite)
- **TCP transport** — deferred to Tier 3 (transport migration)

## References

- Tier 1 plan: `docs/plans/2026-02-05-perf-write-throughput-tier1-quick-wins-plan.md`
- Tier 1 PR: #12
- DotNext `TryGetLeaseToken`: `IRaftCluster.cs:41` in DotNext source
- DotNext `clockDriftBound`: `ClusterMemberConfiguration.cs:55` in DotNext source
- CockroachDB async apply: https://github.com/cockroachdb/cockroach/issues/17500
- Current benchmark results: Tier 1 Locust large tier (10KB payloads, 0% failures)
